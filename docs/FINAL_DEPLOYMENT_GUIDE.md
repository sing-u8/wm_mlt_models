# ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ ì‹œìŠ¤í…œ ìµœì¢… ë°°í¬ ê°€ì´ë“œ

ë³¸ ë¬¸ì„œëŠ” ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ ì‹œìŠ¤í…œì˜ ìµœì¢… ë°°í¬ì™€ ìš´ì˜ì„ ìœ„í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
2. [ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸](#ë°°í¬-ì „-ì²´í¬ë¦¬ìŠ¤íŠ¸)
3. [ëª¨ë¸ ë°°í¬ ë°©ë²•](#ëª¨ë¸-ë°°í¬-ë°©ë²•)
4. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
5. [ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜](#ëª¨ë‹ˆí„°ë§-ë°-ìœ ì§€ë³´ìˆ˜)
6. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

## ğŸ¯ ì‹œìŠ¤í…œ ê°œìš”

### í•µì‹¬ ê¸°ëŠ¥
- **ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ**: 30ì°¨ì› íŠ¹ì§• ë²¡í„° (MFCC, Mel Spectrogram, Spectral Features, Chroma)
- **ë°ì´í„° ì¦ê°•**: SNR ì œì–´ ê¸°ë°˜ ë…¸ì´ì¦ˆ í˜¼í•©
- **ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸**: SVM, Random Forest ë¶„ë¥˜ê¸°
- **ë‹¤ì¤‘ ë°°í¬ í˜•ì‹**: Python Pickle, Core ML
- **ì„±ëŠ¥ ìµœì í™”**: í•˜ë“œì›¨ì–´ë³„ ìë™ ìµœì í™”, ë³‘ë ¬ ì²˜ë¦¬, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±

### ì§€ì› í”Œë«í¼
- **Python**: pickle ëª¨ë¸ì„ ì‚¬ìš©í•œ ì„œë²„/ë°ìŠ¤í¬í†± ë°°í¬
- **iOS/macOS**: Core ML ëª¨ë¸ì„ ì‚¬ìš©í•œ ëª¨ë°”ì¼/ë°ìŠ¤í¬í†± ì•±
- **ì›¹**: Flask/FastAPIë¥¼ í†µí•œ REST API ì„œë¹„ìŠ¤

## âœ… ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì¦
```bash
# ìš”êµ¬ì‚¬í•­ ìë™ ê²€ì¦
cd /Users/parksingyu/PycharmProjects/wm_mlt_models
python validation/requirements_verification.py

# ìµœì†Œ ìš”êµ¬ì‚¬í•­
# - Python 3.7+
# - CPU: 2ì½”ì–´ ì´ìƒ (ê¶Œì¥: 4ì½”ì–´)
# - RAM: 2GB ì´ìƒ (ê¶Œì¥: 8GB)
# - ë””ìŠ¤í¬: 1GB ì—¬ìœ  ê³µê°„ (ê¶Œì¥: 5GB)
```

### 2. ì „ì²´ ì‹œìŠ¤í…œ ê²€ì¦
```bash
# í¬ê´„ì  íŒŒì´í”„ë¼ì¸ ê²€ì¦
python validation/comprehensive_pipeline_validation.py

# ë¹ ë¥¸ ê²€ì¦ (ì‹œê°„ ì ˆì•½)
python validation/comprehensive_pipeline_validation.py --skip-slow
```

### 3. ë°°í¬ ì¤€ë¹„ ìƒíƒœ í™•ì¸
```bash
# ëª¨ë¸ ë°°í¬ ì¤€ë¹„ ìƒíƒœ ê²€ì¦
python validation/deployment_readiness_checker.py

# ê²°ê³¼ í•´ì„:
# - READY: ì¦‰ì‹œ ë°°í¬ ê°€ëŠ¥
# - PARTIALLY_READY: ì¼ë¶€ ê°œì„  í›„ ë°°í¬ ê°€ëŠ¥  
# - NOT_READY: ë¬¸ì œ í•´ê²° í•„ìš”
```

### 4. ë¦¬ì†ŒìŠ¤ ì •ë¦¬
```bash
# ë°°í¬ ì „ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
python src/utils/resource_cleanup.py

# ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ì‚­ì œ X)
python src/utils/resource_cleanup.py --dry-run
```

## ğŸš€ ëª¨ë¸ ë°°í¬ ë°©ë²•

### Python ì„œë²„ ë°°í¬

#### 1. ê¸°ë³¸ ë°°í¬
```python
# ë‹¨ìˆœ ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡
import pickle
import numpy as np
from src.audio.feature_extraction import extract_features
from config import DEFAULT_CONFIG

# ëª¨ë¸ ë¡œë”©
with open('results/trained_models/best_model.pkl', 'rb') as f:
    model = pickle.load(f)

# ì˜ˆì¸¡ í•¨ìˆ˜
def predict_watermelon_class(audio_file_path):
    """ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ ì˜ˆì¸¡"""
    features = extract_features(audio_file_path, DEFAULT_CONFIG)
    if features is None:
        return None
    
    feature_vector = features.to_array().reshape(1, -1)
    prediction = model.predict(feature_vector)[0]
    confidence = model.predict_proba(feature_vector).max()
    
    class_names = ['watermelon_A', 'watermelon_B', 'watermelon_C']
    return {
        'class': class_names[prediction],
        'confidence': float(confidence)
    }
```

#### 2. ìµœì í™”ëœ ë°°í¬
```python
# ìµœì í™”ëœ ë°°í¬ë¥¼ ìœ„í•œ í†µí•© ì‹œìŠ¤í…œ ì‚¬ìš©
from src.optimization.integrated_optimizer import IntegratedOptimizer

# ìë™ ìµœì í™”ê¸° ìƒì„±
optimizer = IntegratedOptimizer()

# ë°°ì¹˜ ì˜ˆì¸¡ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬)
def predict_batch_optimized(audio_files):
    """ìµœì í™”ëœ ë°°ì¹˜ ì˜ˆì¸¡"""
    result = optimizer.process_dataset_optimized(
        audio_files=audio_files,
        extract_features=True,
        perform_augmentation=False
    )
    return result
```

#### 3. Flask ì›¹ ì„œë¹„ìŠ¤
```python
# app.py
from flask import Flask, request, jsonify
import tempfile
import os

app = Flask(__name__)

# ëª¨ë¸ ë¡œë”© (ì•± ì‹œì‘ì‹œ í•œ ë²ˆë§Œ)
with open('results/trained_models/best_model.pkl', 'rb') as f:
    model = pickle.load(f)

@app.route('/predict', methods=['POST'])
def predict():
    """ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ ë° ì˜ˆì¸¡"""
    if 'audio' not in request.files:
        return jsonify({'error': 'ì˜¤ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤'}), 400
    
    audio_file = request.files['audio']
    
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
        audio_file.save(tmp_file.name)
        
        try:
            result = predict_watermelon_class(tmp_file.name)
            return jsonify(result)
        finally:
            os.unlink(tmp_file.name)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### Core ML ëª¨ë°”ì¼ ë°°í¬

#### 1. iOS ë°°í¬ (Swift)
```swift
// WatermelonClassifier.swift
import CoreML
import AVFoundation

class WatermelonClassifier {
    private var model: MLModel?
    
    init() {
        loadModel()
    }
    
    private func loadModel() {
        guard let modelURL = Bundle.main.url(forResource: "watermelon_classifier", withExtension: "mlmodel") else {
            print("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        }
        
        do {
            model = try MLModel(contentsOf: modelURL)
        } catch {
            print("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: \(error)")
        }
    }
    
    func predict(audioFeatures: [Double]) -> (className: String, confidence: Double)? {
        guard let model = model else { return nil }
        
        // íŠ¹ì§• ë²¡í„°ë¥¼ MLMultiArrayë¡œ ë³€í™˜
        guard let featureArray = try? MLMultiArray(shape: [30], dataType: .double) else {
            return nil
        }
        
        for (index, value) in audioFeatures.enumerated() {
            featureArray[index] = NSNumber(value: value)
        }
        
        // ì˜ˆì¸¡ ìˆ˜í–‰
        do {
            let prediction = try model.prediction(from: MLDictionaryFeatureProvider(dictionary: ["input": featureArray]))
            
            if let output = prediction.featureValue(for: "classLabel")?.stringValue,
               let confidence = prediction.featureValue(for: "classProbability")?.dictionaryValue {
                
                let maxConfidence = confidence.values.compactMap { $0.doubleValue }.max() ?? 0.0
                return (className: output, confidence: maxConfidence)
            }
        } catch {
            print("ì˜ˆì¸¡ ì‹¤íŒ¨: \(error)")
        }
        
        return nil
    }
}
```

#### 2. Android ë°°í¬ (Java/Kotlin)
```kotlin
// WatermelonClassifier.kt (TensorFlow Lite ë³€í™˜ í•„ìš”ì‹œ)
import org.tensorflow.lite.Interpreter
import java.nio.ByteBuffer
import java.nio.ByteOrder

class WatermelonClassifier(private val modelPath: String) {
    private var interpreter: Interpreter? = null
    
    init {
        loadModel()
    }
    
    private fun loadModel() {
        try {
            val model = loadModelFile(modelPath)
            interpreter = Interpreter(model)
        } catch (e: Exception) {
            e.printStackTrace()
        }
    }
    
    fun predict(features: FloatArray): Pair<String, Float>? {
        val interpreter = this.interpreter ?: return null
        
        // ì…ë ¥ ì¤€ë¹„
        val inputBuffer = ByteBuffer.allocateDirect(4 * features.size)
        inputBuffer.order(ByteOrder.nativeOrder())
        
        features.forEach { inputBuffer.putFloat(it) }
        
        // ì¶œë ¥ ì¤€ë¹„
        val outputBuffer = ByteBuffer.allocateDirect(4 * 3) // 3 classes
        outputBuffer.order(ByteOrder.nativeOrder())
        
        // ì˜ˆì¸¡
        interpreter.run(inputBuffer, outputBuffer)
        
        // ê²°ê³¼ íŒŒì‹±
        outputBuffer.rewind()
        val probabilities = FloatArray(3)
        outputBuffer.asFloatBuffer().get(probabilities)
        
        val maxIndex = probabilities.indices.maxByOrNull { probabilities[it] } ?: 0
        val classNames = arrayOf("watermelon_A", "watermelon_B", "watermelon_C")
        
        return Pair(classNames[maxIndex], probabilities[maxIndex])
    }
}
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. í•˜ë“œì›¨ì–´ë³„ ìë™ ìµœì í™”
```python
# ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ì— ë§ëŠ” ìë™ ìµœì í™”
from src.config.hardware_config import get_hardware_config

# í˜„ì¬ í•˜ë“œì›¨ì–´ ì„¤ì • í™•ì¸
config_manager = get_hardware_config()
config_manager.print_system_info()

# í”„ë¦¬ì…‹ ë³€ê²½ (í•„ìš”ì‹œ)
config_manager.set_preset('high_performance')  # ë˜ëŠ” 'balanced', 'low_memory'
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
```python
# ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬
from src.audio.batch_processor import extract_features_batch, BatchProcessingConfig

# ìµœì í™”ëœ ë°°ì¹˜ ì„¤ì •
config = BatchProcessingConfig(
    max_workers=4,
    chunk_size=32,
    use_multiprocessing=True,
    cache_features=True
)

# ë°°ì¹˜ íŠ¹ì§• ì¶”ì¶œ
audio_files = ['file1.wav', 'file2.wav', ...]
result = extract_features_batch(audio_files, config)

print(f"ì²˜ë¦¬ëœ íŒŒì¼: {result.success_count}/{len(audio_files)}")
print(f"ì´ ì‹œê°„: {result.total_time:.2f}ì´ˆ")
print(f"í‰ê·  ì†ë„: {result.success_count/result.total_time:.1f} files/sec")
```

### 3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
from src.data.large_dataset_processor import process_large_dataset_memory_efficient

result = process_large_dataset_memory_efficient(
    audio_files=large_file_list,
    memory_limit_gb=2.0,  # ë©”ëª¨ë¦¬ ì œí•œ
    include_features=True,
    progress_callback=lambda p: print(f"ì§„í–‰ë¥ : {p:.1%}")
)
```

### 4. ë³‘ë ¬ ë°ì´í„° ì¦ê°•
```python
# ë³‘ë ¬ ë°ì´í„° ì¦ê°•
from src.data.parallel_augmentor import augment_directory_parallel, ParallelAugmentationConfig

config = ParallelAugmentationConfig(
    max_workers=4,
    chunk_size=16,
    snr_levels=[0, 5, 10],
    use_multiprocessing=True
)

result = augment_directory_parallel(
    audio_dir='data/raw/train/watermelon_A',
    noise_dir='data/noise',
    output_dir='data/augmented',
    config=config
)
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜

### 1. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```python
# ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
from src.optimization.integrated_optimizer import IntegratedOptimizer

optimizer = IntegratedOptimizer()
benchmark = optimizer.benchmark_system()

print(f"íŠ¹ì§• ì¶”ì¶œ ì†ë„: {benchmark['feature_extraction']['files_per_second']:.1f} files/sec")
print(f"ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {benchmark['feature_extraction']['memory_efficiency']:.1%}")
```

### 2. ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```python
# ì˜ˆì¸¡ ê²°ê³¼ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
import logging
from datetime import datetime

def predict_with_monitoring(audio_file):
    """ëª¨ë‹ˆí„°ë§ì´ í¬í•¨ëœ ì˜ˆì¸¡"""
    start_time = time.time()
    
    try:
        result = predict_watermelon_class(audio_file)
        processing_time = time.time() - start_time
        
        # ì„±ëŠ¥ ë¡œê¹…
        logging.info(f"ì˜ˆì¸¡ ì„±ê³µ: {audio_file}, ì‹œê°„: {processing_time:.3f}ì´ˆ, "
                    f"ê²°ê³¼: {result['class']}, ì‹ ë¢°ë„: {result['confidence']:.3f}")
        
        return result
        
    except Exception as e:
        logging.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {audio_file}, ì˜¤ë¥˜: {str(e)}")
        return None
```

### 3. ìë™ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
```python
# ì£¼ê¸°ì  ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (í¬ë¡ ì¡ ë“±ì—ì„œ ì‹¤í–‰)
from src.utils.resource_cleanup import quick_cleanup

# 24ì‹œê°„ ì´ì „ ì„ì‹œ íŒŒì¼ ì •ë¦¬
report = quick_cleanup(preserve_hours=24, dry_run=False)
print(f"ì •ë¦¬ëœ ê³µê°„: {report.disk_space_freed_mb:.1f}MB")
```

### 4. ëª¨ë¸ ì—…ë°ì´íŠ¸ ë° A/B í…ŒìŠ¤íŠ¸
```python
# ëª¨ë¸ ë²„ì „ ê´€ë¦¬
class ModelVersionManager:
    def __init__(self):
        self.models = {}
        self.current_version = 'v1.0'
    
    def load_model_version(self, version: str, model_path: str):
        """íŠ¹ì • ë²„ì „ ëª¨ë¸ ë¡œë”©"""
        with open(model_path, 'rb') as f:
            self.models[version] = pickle.load(f)
    
    def predict_with_version(self, audio_file: str, version: str = None):
        """ì§€ì •ëœ ë²„ì „ìœ¼ë¡œ ì˜ˆì¸¡"""
        version = version or self.current_version
        model = self.models.get(version)
        
        if not model:
            raise ValueError(f"ëª¨ë¸ ë²„ì „ {version}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì˜ˆì¸¡ ë¡œì§...
        return self._predict_with_model(model, audio_file)
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
```bash
# í•´ê²° ë°©ë²•
# 1. ë©”ëª¨ë¦¬ íš¨ìœ¨ ëª¨ë“œ ì‚¬ìš©
python main.py --memory-limit 2.0

# 2. ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í™œì„±í™”
# src/optimization/integrated_optimizer.pyì—ì„œ enable_streaming=True

# 3. ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
# BatchProcessingConfigì—ì„œ chunk_size ê°ì†Œ
```

#### 2. ì„±ëŠ¥ ì €í•˜
```python
# ì„±ëŠ¥ ì§„ë‹¨ ë° ìµœì í™”
from src.config.hardware_config import get_hardware_config

config = get_hardware_config()
config.print_system_info()

# í•˜ë“œì›¨ì–´ì— ë§ëŠ” í”„ë¦¬ì…‹ ìë™ ì ìš©
config.auto_configure()
```

#### 3. ëª¨ë¸ ì˜ˆì¸¡ ì˜¤ë¥˜
```python
# ëª¨ë¸ ë¬´ê²°ì„± ê²€ì¦
from validation.deployment_readiness_checker import DeploymentReadinessChecker

checker = DeploymentReadinessChecker()
report = checker.run_comprehensive_deployment_check()

if report.overall_status != "READY":
    print("ëª¨ë¸ ë¬¸ì œ ë°œê²¬:")
    for issue in report.critical_issues:
        print(f"  - {issue}")
```

#### 4. Core ML ë³€í™˜ ì‹¤íŒ¨
```bash
# Core ML ë„êµ¬ ì„¤ì¹˜ ë° ì—…ë°ì´íŠ¸
pip install --upgrade coremltools

# Python í™˜ê²½ì—ì„œ ë³€í™˜ í…ŒìŠ¤íŠ¸
python -c "
from src.ml.model_converter import ModelConverter
converter = ModelConverter()
# ë³€í™˜ í…ŒìŠ¤íŠ¸ ì½”ë“œ...
"
```

### ë¡œê·¸ ë¶„ì„
```bash
# ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜
ls logs/

# ìµœê·¼ ì˜¤ë¥˜ í™•ì¸
tail -f logs/main.log | grep ERROR

# ì„±ëŠ¥ ë¡œê·¸ ë¶„ì„
grep "ì²˜ë¦¬ ì‹œê°„" logs/main.log | tail -20
```

### ë””ë²„ê¹… ëª¨ë“œ ì‹¤í–‰
```bash
# ìƒì„¸ ë””ë²„ê¹… ì •ë³´ì™€ í•¨ê»˜ ì‹¤í–‰
python main.py --debug --verbose

# íŠ¹ì • ëª¨ë“ˆ ë””ë²„ê¹…
export PYTHONPATH=.
python -m src.audio.feature_extraction --debug
```

## ğŸ“ ì§€ì› ë° ì—°ë½ì²˜

### ê°œë°œíŒ€ ì—°ë½ì²˜
- **ê¸°ìˆ  ì§€ì›**: tech-support@company.com
- **ë²„ê·¸ ë¦¬í¬íŠ¸**: GitHub Issues
- **ì„±ëŠ¥ ìµœì í™” ë¬¸ì˜**: performance@company.com

### ì°¸ê³  ë¬¸ì„œ
- [API ë ˆí¼ëŸ°ìŠ¤](API_REFERENCE.md)
- [ëª¨ë¸ ì‚¬ìš© ì˜ˆì œ](MODEL_USAGE_EXAMPLES.md)
- [ì‚¬ìš©ë²• ì˜ˆì œ](USAGE_EXAMPLES.md)
- [Core ML ì‚¬ìš©ë²•](COREML_USAGE.md)

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2024ë…„ 12ì›” 
**ë¬¸ì„œ ë²„ì „**: 1.0
**ì‹œìŠ¤í…œ ë²„ì „**: ìµœì¢… ì™„ì„± ë²„ì „