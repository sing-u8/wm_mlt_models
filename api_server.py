from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import os
import uuid
import joblib
import numpy as np
import uvicorn
import sys
import logging
import json
from datetime import datetime
from pathlib import Path

from src.audio.feature_extraction import extract_features, AudioFeatureExtractor
from config.config import DEFAULT_CONFIG


# JSON ì§ë ¬í™” ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í´ë˜ìŠ¤ ì •ì˜
class NumpyEncoder(json.JSONEncoder):
    """NumPy ë°ì´í„° íƒ€ì…ì„ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ê¸° ìœ„í•œ ì¸ì½”ë”"""

    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)


# ë¡œê¹… ì„¤ì • - ë” ìƒì„¸í•œ í¬ë§·
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('feature_extraction.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ì„œë²„", description="ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ìˆ˜ë°•ì˜ ë‹¹ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš©, ë°°í¬ì‹œì—ëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë¸ ë¡œë“œ
MODEL_PATH = os.path.join(DEFAULT_CONFIG.model_output_dir, "pickle", "random_forest_model.pkl")

try:
    model_bundle = joblib.load(MODEL_PATH)
    if isinstance(model_bundle, dict):
        model = model_bundle["model"]
        logger.info(f"ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {MODEL_PATH} (ë”•ì…”ë„ˆë¦¬ì—ì„œ 'model' í‚¤ ì‚¬ìš©)")
    else:
        model = model_bundle
        logger.info(f"ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {MODEL_PATH} (ì§ì ‘ ëª¨ë¸ ê°ì²´ ì‚¬ìš©)")

    # ëª¨ë¸ ì •ë³´ ë¡œê¹…
    if hasattr(model, 'n_features_in_'):
        logger.info(f"ëª¨ë¸ íŠ¹ì„± ìˆ˜: {model.n_features_in_}")
    if hasattr(model, 'classes_'):
        logger.info(f"ëª¨ë¸ í´ë˜ìŠ¤: {model.classes_}")
    if hasattr(model, 'n_estimators'):
        logger.info(f"Random Forest íŠ¸ë¦¬ ìˆ˜: {model.n_estimators}")

except Exception as e:
    logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    model = None


def log_audio_info(y, sr, file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ë¡œê¹…"""
    duration = len(y) / sr
    max_amplitude = np.max(np.abs(y))
    rms_energy = np.sqrt(np.mean(y ** 2))

    logger.info(f"ğŸ“ íŒŒì¼ ì •ë³´: {os.path.basename(file_path)}")
    logger.info(f"   - ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr} Hz")
    logger.info(f"   - ê¸¸ì´: {duration:.2f}ì´ˆ ({len(y)} ìƒ˜í”Œ)")
    logger.info(f"   - ìµœëŒ€ ì§„í­: {max_amplitude:.6f}")
    logger.info(f"   - RMS ì—ë„ˆì§€: {rms_energy:.6f}")
    logger.info(f"   - ë‹¤ì´ë‚˜ë¯¹ ë ˆì¸ì§€: {20 * np.log10(max_amplitude / (rms_energy + 1e-8)):.2f} dB")


def log_feature_details(feature_vector):
    """ì¶”ì¶œëœ íŠ¹ì„±ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë¡œê¹…"""
    feature_array = feature_vector.to_array()
    feature_names = feature_vector.feature_names

    logger.info(f"ğŸ” íŠ¹ì„± ë¶„ì„:")
    logger.info(f"   - íŠ¹ì„± ê°œìˆ˜: {len(feature_array)}")
    logger.info(f"   - ê°’ ë²”ìœ„: [{np.min(feature_array):.6f}, {np.max(feature_array):.6f}]")
    logger.info(f"   - í‰ê· ê°’: {np.mean(feature_array):.6f}")
    logger.info(f"   - í‘œì¤€í¸ì°¨: {np.std(feature_array):.6f}")

    # MFCC ìƒì„¸ ì •ë³´
    logger.info(f"   - MFCC ê³„ìˆ˜ ìƒì„¸:")
    for i, val in enumerate(feature_vector.mfcc):
        logger.info(f"     [{i + 1:2d}] {val:10.6f}")

    # Chroma ìƒì„¸ ì •ë³´
    logger.info(f"   - Chroma ê³„ìˆ˜ ìƒì„¸:")
    for i, val in enumerate(feature_vector.chroma):
        logger.info(f"     [{i + 1:2d}] {val:10.6f}")


def save_features_to_json(feature_vector, file_path):
    """íŠ¹ì„±ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        feature_array = feature_vector.to_array()
        feature_names = feature_vector.feature_names

        feature_data = {
            "timestamp": datetime.now().isoformat(),
            "source_file": os.path.basename(file_path),
            "feature_count": len(feature_array),
            "features": {
                name: float(value) for name, value in zip(feature_names, feature_array)
            },
            "statistics": {
                "min": float(np.min(feature_array)),
                "max": float(np.max(feature_array)),
                "mean": float(np.mean(feature_array)),
                "std": float(np.std(feature_array)),
                "median": float(np.median(feature_array))
            }
        }

        json_filename = f"features_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(feature_data, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ’¾ íŠ¹ì„± ë°ì´í„° ì €ì¥ë¨: {json_filename}")
        return json_filename

    except Exception as e:
        logger.warning(f"íŠ¹ì„± JSON ì €ì¥ ì‹¤íŒ¨: {e}")
        return None


# ì„œë²„ ìƒíƒœ í™•ì¸
@app.get("/health")
def health_check():
    return {
        "status": "healthy",
        "message": "ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤",
        "model_loaded": model is not None,
        "timestamp": datetime.now().isoformat()
    }


# ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ ì •ë³´
@app.get("/supported-formats")
def get_supported_formats():
    return {
        "formats": [".wav", ".m4a", ".mp3"],
        "description": "ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ í˜•ì‹"
    }


# íŠ¹ì„± ì •ë³´ API (ë””ë²„ê¹…ìš©)
@app.get("/feature-info")
def get_feature_info():
    return {
        "total_features": DEFAULT_CONFIG.n_mfcc + 5 + DEFAULT_CONFIG.n_chroma,  # 13 + 5 + 12 = 30
        "feature_groups": {
            "mfcc": {"count": DEFAULT_CONFIG.n_mfcc, "description": "Mel-frequency cepstral coefficients"},
            "mel_spectrogram": {"count": 2, "description": "ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì˜ í†µê³„ (í‰ê· , í‘œì¤€í¸ì°¨)"},
            "spectral": {"count": 2, "description": "ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§• (ì¤‘ì‹¬, ë¡¤ì˜¤í”„)"},
            "zcr": {"count": 1, "description": "Zero crossing rate"},
            "chroma": {"count": DEFAULT_CONFIG.n_chroma, "description": "Chroma features"}
        },
        "model_type": model.__class__.__name__ if model else "ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨",
        "classes": [int(c) for c in model.classes_] if hasattr(model, 'classes_') else ["ì•Œ ìˆ˜ ì—†ìŒ"]
    }


# ë””ë²„ê¹…ìš© íŠ¹ì„± ë¶„ì„ API
@app.post("/debug-features")
async def debug_features(file: UploadFile = File(...)):
    """íŠ¹ì„± ì¶”ì¶œ ë””ë²„ê¹… ì „ìš© API"""
    temp_path = None
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì‚¬
        ext = os.path.splitext(file.filename)[-1].lower()
        if ext not in [".wav", ".m4a", ".mp3"]:
            return JSONResponse(
                status_code=400,
                content={"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .wav, .m4a, .mp3 íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."}
            )

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = f"debug_{uuid.uuid4()}{ext}"
        with open(temp_path, "wb") as f:
            f.write(await file.read())

        logger.info(f"ë””ë²„ê¹…ìš© íŒŒì¼ ì €ì¥: {file.filename} -> {temp_path}")

        # íŠ¹ì„± ì¶”ì¶œ
        feature_vector = extract_features(temp_path)
        if feature_vector is None:
            return JSONResponse(
                status_code=400,
                content={"error": "ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ íŠ¹ì„± ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
            )

        # íŠ¹ì„± ìƒì„¸ ì •ë³´ ë¡œê¹…
        log_feature_details(feature_vector)

        # íŠ¹ì„± ì €ì¥
        json_filename = save_features_to_json(feature_vector, temp_path)

        # ê²°ê³¼ ë°˜í™˜
        feature_array = feature_vector.to_array()
        feature_names = feature_vector.feature_names

        result = {
            "success": True,
            "filename": file.filename,
            "feature_count": len(feature_array),
            "features": {
                name: float(value) for name, value in zip(feature_names, feature_array)
            },
            "statistics": {
                "min": float(np.min(feature_array)),
                "max": float(np.max(feature_array)),
                "mean": float(np.mean(feature_array)),
                "std": float(np.std(feature_array)),
                "median": float(np.median(feature_array))
            },
            "quality_check": {
                "nan_count": int(np.sum(np.isnan(feature_array))),
                "inf_count": int(np.sum(np.isinf(feature_array))),
                "is_valid": bool(np.all(np.isfinite(feature_array)))
            }
        }

        if json_filename:
            result["saved_to"] = json_filename

        return JSONResponse(content=result)

    except Exception as e:
        logger.error(f"ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={"error": f"ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}
        )
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
                logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


# ì˜ˆì¸¡ API
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ìˆ˜ë°• ë‹¹ë„ë¥¼ ì˜ˆì¸¡"""
    if model is None:
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        )

    temp_path = None
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì‚¬
        ext = os.path.splitext(file.filename)[-1].lower()
        if ext not in [".wav", ".m4a", ".mp3"]:
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .wav, .m4a, .mp3 íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                }
            )

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = f"temp_{uuid.uuid4()}{ext}"
        with open(temp_path, "wb") as f:
            f.write(await file.read())

        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} -> {temp_path}")

        # íŠ¹ì„± ì¶”ì¶œ
        feature_vector = extract_features(temp_path)
        if feature_vector is None:
            return JSONResponse(
                status_code=400,
                content={"success": False, "error": "ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ íŠ¹ì„± ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
            )

        feature_array = feature_vector.to_array().reshape(1, -1)

        # ë””ë²„ê¹…: ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” feature ê°œìˆ˜, ì‹¤ì œ feature vector ì •ë³´ ì¶œë ¥
        logger.info(f"[predict] model.n_features_in_: {getattr(model, 'n_features_in_', None)}")
        logger.info(f"[predict] feature_array.shape: {feature_array.shape}")
        logger.info(f"[predict] feature_array dtype: {feature_array.dtype}")

        # ì˜ˆì¸¡
        prediction = model.predict(feature_array)[0]
        probability = model.predict_proba(feature_array)[0] if hasattr(model, 'predict_proba') else None

        # ì˜ˆì¸¡ í´ë˜ìŠ¤ ì´ë¦„ (ëª¨ë¸ í´ë˜ìŠ¤ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        if hasattr(model, 'classes_'):
            predicted_class = int(model.classes_[prediction])
        else:
            predicted_class = f"class_{prediction}"

        logger.info(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: {prediction} (í´ë˜ìŠ¤: {predicted_class})")
        if probability is not None:
            logger.info(f"   - í™•ë¥  ë¶„í¬: {probability}")
            logger.info(f"   - ìµœëŒ€ í™•ë¥ : {max(probability):.4f}")

        # ê²°ê³¼ ë°˜í™˜
        result = {
            "success": True,
            "filename": file.filename,
            "prediction": int(prediction),
            "predicted_class": predicted_class,
            "confidence": float(max(probability)) if probability is not None else None
        }

        # í™•ë¥  ë¶„í¬ ì •ë³´ ì¶”ê°€ (í´ë˜ìŠ¤ë³„)
        if probability is not None and hasattr(model, 'classes_'):
            result["probabilities"] = {
                str(int(cls)): float(prob) for cls, prob in zip(model.classes_, probability)
            }

        # NumPy ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ JSON ì§ë ¬í™”
        return JSONResponse(content=json.loads(json.dumps(result, cls=NumpyEncoder)))

    except Exception as e:
        logger.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
        )
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
                logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    import socket


    def get_local_ip():
        """ë¡œì»¬ ë„¤íŠ¸ì›Œí¬ IP ì£¼ì†Œë¥¼ ë°˜í™˜"""
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            ip = s.getsockname()[0]
            s.close()
            return ip
        except:
            return "127.0.0.1"


    # ì‹¤í–‰ ì•ˆë‚´ ì •ë³´ ì¶œë ¥
    local_ip = get_local_ip()
    print(f"ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ì„œë²„ ì‹œì‘")
    print(f"   - ë¡œì»¬: http://localhost:9001")
    print(f"   - ë„¤íŠ¸ì›Œí¬: http://{local_ip}:9001")
    print(f"   - ìƒíƒœ í™•ì¸: http://{local_ip}:9001/health")
    print(f"   - íŠ¹ì„± ë””ë²„ê¹…: http://{local_ip}:9001/debug-features")
    print(f"   - ì˜ˆì¸¡ API: http://{local_ip}:9001/predict")

    uvicorn.run(app, host="0.0.0.0", port=9001)