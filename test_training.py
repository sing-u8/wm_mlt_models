#!/usr/bin/env python3
"""
ë¨¸ì‹ ëŸ¬ë‹ í›ˆë ¨ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ModelTrainer í´ë˜ìŠ¤ ë° êµì°¨ ê²€ì¦ ê¸°ëŠ¥ ê²€ì¦
"""

import sys
import os
import tempfile
import shutil
import numpy as np
from pathlib import Path
import joblib
import json
sys.path.append('.')

from src.ml.training import ModelTrainer, ModelConfig, TrainingResult, ModelArtifact
from src.utils.logger import setup_logger
from config import DEFAULT_CONFIG

def create_test_dataset():
    """í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ ë°ì´í„°ì…‹ ìƒì„±"""
    np.random.seed(42)
    
    # 30ì°¨ì› íŠ¹ì§• ë²¡í„° (design.md ëª…ì„¸)
    n_samples = 150
    n_features = 30
    n_classes = 3
    
    # ê° í´ë˜ìŠ¤ë³„ë¡œ 50ê°œ ìƒ˜í”Œ ìƒì„±
    X = []
    y = []
    
    for class_idx in range(n_classes):
        # í´ë˜ìŠ¤ë³„ë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ë°ì´í„° ìƒì„±
        class_center = np.random.randn(n_features) * 2
        class_samples = np.random.randn(50, n_features) + class_center
        
        X.append(class_samples)
        y.extend([class_idx] * 50)
    
    X = np.vstack(X)
    y = np.array(y)
    
    # ë°ì´í„° ì…”í”Œ
    indices = np.random.permutation(len(X))
    X = X[indices]
    y = y[indices]
    
    # train/validation/test ë¶„í• 
    train_size = int(0.7 * len(X))
    val_size = int(0.2 * len(X))
    
    X_train = X[:train_size]
    y_train = y[:train_size]
    
    X_val = X[train_size:train_size + val_size]
    y_val = y[train_size:train_size + val_size]
    
    X_test = X[train_size + val_size:]
    y_test = y[train_size + val_size:]
    
    return X_train, y_train, X_val, y_val, X_test, y_test

def test_model_trainer_initialization():
    """ModelTrainer ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    
    logger = setup_logger("trainer_init_test", "INFO")
    logger.info("=== ModelTrainer ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # ê¸°ë³¸ êµ¬ì„±ìœ¼ë¡œ ì´ˆê¸°í™”
        trainer = ModelTrainer()
        
        # ëª¨ë¸ êµ¬ì„± í™•ì¸
        expected_models = ["svm", "random_forest"]
        actual_models = list(trainer.models.keys())
        
        if set(expected_models) == set(actual_models):
            logger.info(f"âœ… ëª¨ë¸ êµ¬ì„± ì˜¬ë°”ë¦„: {actual_models}")
        else:
            logger.error(f"âŒ ëª¨ë¸ êµ¬ì„± ì˜¤ë¥˜: ì˜ˆìƒ {expected_models}, ì‹¤ì œ {actual_models}")
            return False
        
        # SVM êµ¬ì„± í™•ì¸
        svm_config = trainer.models["svm"]
        if svm_config.model_type == "svm" and "C" in svm_config.param_grid:
            logger.info("âœ… SVM êµ¬ì„± ì˜¬ë°”ë¦„")
        else:
            logger.error("âŒ SVM êµ¬ì„± ì˜¤ë¥˜")
            return False
        
        # Random Forest êµ¬ì„± í™•ì¸
        rf_config = trainer.models["random_forest"]
        if rf_config.model_type == "random_forest" and "n_estimators" in rf_config.param_grid:
            logger.info("âœ… Random Forest êµ¬ì„± ì˜¬ë°”ë¦„")
        else:
            logger.error("âŒ Random Forest êµ¬ì„± ì˜¤ë¥˜")
            return False
        
        logger.info("âœ… ModelTrainer ì´ˆê¸°í™” ì„±ê³µ")
        return True
        
    except Exception as e:
        logger.error(f"ModelTrainer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    finally:
        logger.info("=== ModelTrainer ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\n")

def test_single_model_training():
    """ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸"""
    
    logger = setup_logger("single_model_test", "INFO")
    logger.info("=== ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        X_train, y_train, X_val, y_val, X_test, y_test = create_test_dataset()
        logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {X_train.shape} í›ˆë ¨ ìƒ˜í”Œ")
        
        # ModelTrainer ì´ˆê¸°í™”
        trainer = ModelTrainer()
        
        # SVM ëª¨ë¸ í›ˆë ¨
        logger.info("SVM ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        svm_result = trainer.train_single_model("svm", X_train, y_train, cv_folds=3)
        
        # ê²°ê³¼ ê²€ì¦
        if isinstance(svm_result, TrainingResult):
            logger.info(f"âœ… SVM í›ˆë ¨ ì™„ë£Œ:")
            logger.info(f"  ìµœì  ì ìˆ˜: {svm_result.best_score:.4f}")
            logger.info(f"  ìµœì  íŒŒë¼ë¯¸í„°: {svm_result.best_params}")
            logger.info(f"  í›ˆë ¨ ì‹œê°„: {svm_result.training_time:.2f}ì´ˆ")
        else:
            logger.error("âŒ SVM í›ˆë ¨ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜")
            return False
        
        # Random Forest ëª¨ë¸ í›ˆë ¨ (ë” ì‘ì€ ê·¸ë¦¬ë“œë¡œ)
        logger.info("Random Forest ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì¶•ì†Œ
        original_rf_grid = trainer.models["random_forest"].param_grid
        trainer.models["random_forest"].param_grid = {
            "n_estimators": [50, 100],
            "max_depth": [None, 10],
            "min_samples_split": [2, 5]
        }
        
        rf_result = trainer.train_single_model("random_forest", X_train, y_train, cv_folds=3)
        
        # ì›ë˜ ê·¸ë¦¬ë“œ ë³µì›
        trainer.models["random_forest"].param_grid = original_rf_grid
        
        if isinstance(rf_result, TrainingResult):
            logger.info(f"âœ… Random Forest í›ˆë ¨ ì™„ë£Œ:")
            logger.info(f"  ìµœì  ì ìˆ˜: {rf_result.best_score:.4f}")
            logger.info(f"  ìµœì  íŒŒë¼ë¯¸í„°: {rf_result.best_params}")
            logger.info(f"  í›ˆë ¨ ì‹œê°„: {rf_result.training_time:.2f}ì´ˆ")
            logger.info(f"  íŠ¹ì§• ì¤‘ìš”ë„ ê°œìˆ˜: {len(rf_result.feature_importance) if rf_result.feature_importance else 0}")
        else:
            logger.error("âŒ Random Forest í›ˆë ¨ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜")
            return False
        
        logger.info("âœ… ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨ ì„±ê³µ")
        return True
        
    except Exception as e:
        logger.error(f"ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        logger.info("=== ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\n")

def test_cross_validation_training():
    """êµì°¨ ê²€ì¦ í›ˆë ¨ í…ŒìŠ¤íŠ¸"""
    
    logger = setup_logger("cv_training_test", "INFO")
    logger.info("=== êµì°¨ ê²€ì¦ í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        X_train, y_train, X_val, y_val, X_test, y_test = create_test_dataset()
        
        # ModelTrainer ì´ˆê¸°í™”
        trainer = ModelTrainer()
        
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì¶•ì†Œ
        trainer.models["svm"].param_grid = {
            "C": [1, 10],
            "gamma": ["scale", "auto"]
        }
        trainer.models["random_forest"].param_grid = {
            "n_estimators": [50],
            "max_depth": [None, 10],
            "min_samples_split": [2]
        }
        
        # ëª¨ë“  ëª¨ë¸ êµì°¨ ê²€ì¦ í›ˆë ¨
        logger.info("ëª¨ë“  ëª¨ë¸ êµì°¨ ê²€ì¦ í›ˆë ¨ ì‹œì‘...")
        all_results = trainer.train_with_cv(X_train, y_train, cv_folds=3)
        
        if len(all_results) != 2:
            logger.error(f"âŒ ì˜ˆìƒ ëª¨ë¸ ìˆ˜ 2ê°œ, ì‹¤ì œ {len(all_results)}ê°œ")
            return False
        
        # ê²°ê³¼ ê²€ì¦
        for model_type, result in all_results.items():
            if not isinstance(result, TrainingResult):
                logger.error(f"âŒ {model_type} ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜")
                return False
            
            logger.info(f"âœ… {model_type} í›ˆë ¨ ì™„ë£Œ:")
            logger.info(f"  ìµœì  ì ìˆ˜: {result.best_score:.4f}")
            logger.info(f"  CV ì ìˆ˜ ê°œìˆ˜: {len(result.cv_scores)}")
            logger.info(f"  íŠ¹ì§• ê°œìˆ˜: {result.n_features}")
            logger.info(f"  ìƒ˜í”Œ ê°œìˆ˜: {result.n_samples}")
        
        # í›ˆë ¨ëœ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if len(trainer.trained_models) == 2:
            logger.info("âœ… ëª¨ë“  ëª¨ë¸ì´ ë‚´ë¶€ì— ì €ì¥ë¨")
        else:
            logger.error(f"âŒ ì €ì¥ëœ ëª¨ë¸ ìˆ˜ ì˜¤ë¥˜: {len(trainer.trained_models)}")
            return False
        
        logger.info("âœ… êµì°¨ ê²€ì¦ í›ˆë ¨ ì„±ê³µ")
        return True
        
    except Exception as e:
        logger.error(f"êµì°¨ ê²€ì¦ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        logger.info("=== êµì°¨ ê²€ì¦ í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\n")

def test_model_evaluation():
    """ëª¨ë¸ í‰ê°€ í…ŒìŠ¤íŠ¸"""
    
    logger = setup_logger("evaluation_test", "INFO")
    logger.info("=== ëª¨ë¸ í‰ê°€ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        X_train, y_train, X_val, y_val, X_test, y_test = create_test_dataset()
        
        # ModelTrainer ì´ˆê¸°í™” ë° í›ˆë ¨
        trainer = ModelTrainer()
        
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê·¸ë¦¬ë“œ ì¶•ì†Œ
        trainer.models["svm"].param_grid = {"C": [1], "gamma": ["scale"]}
        trainer.models["random_forest"].param_grid = {"n_estimators": [50], "max_depth": [10]}
        
        # ëª¨ë¸ í›ˆë ¨
        all_results = trainer.train_with_cv(X_train, y_train, cv_folds=3)
        
        # ê°œë³„ ëª¨ë¸ í‰ê°€
        logger.info("ê°œë³„ ëª¨ë¸ í‰ê°€ ì‹œì‘...")
        svm_metrics = trainer.evaluate_single_model("svm", X_test, y_test)
        
        # í‰ê°€ ë©”íŠ¸ë¦­ í™•ì¸
        expected_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
        for metric in expected_metrics:
            if metric not in svm_metrics:
                logger.error(f"âŒ SVM í‰ê°€ì—ì„œ {metric} ë©”íŠ¸ë¦­ ëˆ„ë½")
                return False
        
        logger.info(f"âœ… SVM í‰ê°€ ì™„ë£Œ: ì •í™•ë„ {svm_metrics['accuracy']:.4f}")
        
        # ì „ì²´ ëª¨ë¸ í‰ê°€
        logger.info("ì „ì²´ ëª¨ë¸ í‰ê°€ ì‹œì‘...")
        all_metrics = trainer.evaluate_final(X_test, y_test)
        
        if len(all_metrics) != 2:
            logger.error(f"âŒ í‰ê°€ëœ ëª¨ë¸ ìˆ˜ ì˜¤ë¥˜: {len(all_metrics)}")
            return False
        
        for model_type, metrics in all_metrics.items():
            logger.info(f"âœ… {model_type} ìµœì¢… í‰ê°€:")
            logger.info(f"  ì •í™•ë„: {metrics['accuracy']:.4f}")
            logger.info(f"  F1 (macro): {metrics['f1_macro']:.4f}")
        
        logger.info("âœ… ëª¨ë¸ í‰ê°€ ì„±ê³µ")
        return True
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        logger.info("=== ëª¨ë¸ í‰ê°€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\n")

def test_model_saving_and_loading():
    """ëª¨ë¸ ì €ì¥ ë° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    
    logger = setup_logger("save_load_test", "INFO")
    logger.info("=== ëª¨ë¸ ì €ì¥ ë° ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        X_train, y_train, X_val, y_val, X_test, y_test = create_test_dataset()
        
        # ModelTrainer ì´ˆê¸°í™” ë° í›ˆë ¨
        trainer = ModelTrainer()
        
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê·¸ë¦¬ë“œ ì¶•ì†Œ
        trainer.models["svm"].param_grid = {"C": [1], "gamma": ["scale"]}
        trainer.models["random_forest"].param_grid = {"n_estimators": [50]}
        
        # ëª¨ë¸ í›ˆë ¨
        all_results = trainer.train_with_cv(X_train, y_train, cv_folds=3)
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ ì €ì¥
        with tempfile.TemporaryDirectory() as temp_dir:
            logger.info(f"ì„ì‹œ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ ì €ì¥: {temp_dir}")
            
            # ëª¨ë¸ ì €ì¥
            saved_paths = trainer.save_models(temp_dir)
            
            if len(saved_paths) != 2:
                logger.error(f"âŒ ì €ì¥ëœ ëª¨ë¸ ìˆ˜ ì˜¤ë¥˜: {len(saved_paths)}")
                return False
            
            # ì €ì¥ëœ íŒŒì¼ í™•ì¸
            for model_type, path in saved_paths.items():
                if not os.path.exists(path):
                    logger.error(f"âŒ {model_type} ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {path}")
                    return False
                
                # ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸
                config_path = os.path.join(temp_dir, f"{model_type}_config.json")
                if not os.path.exists(config_path):
                    logger.error(f"âŒ {model_type} ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                    return False
                
                logger.info(f"âœ… {model_type} ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            
            # ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
            for model_type, path in saved_paths.items():
                loaded_model = trainer.load_model(path)
                
                # ë¡œë”©ëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
                predictions = loaded_model.predict(X_test[:5])  # ì²˜ìŒ 5ê°œ ìƒ˜í”Œë§Œ
                
                if len(predictions) == 5:
                    logger.info(f"âœ… {model_type} ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡ ì„±ê³µ")
                else:
                    logger.error(f"âŒ {model_type} ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨")
                    return False
            
            # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ í™•ì¸
            for model_type in saved_paths.keys():
                if model_type in trainer.model_artifacts:
                    artifact = trainer.model_artifacts[model_type]
                    if isinstance(artifact, ModelArtifact):
                        logger.info(f"âœ… {model_type} ì•„í‹°íŒ©íŠ¸ ìƒì„± ì™„ë£Œ")
                    else:
                        logger.error(f"âŒ {model_type} ì•„í‹°íŒ©íŠ¸ í˜•ì‹ ì˜¤ë¥˜")
                        return False
        
        logger.info("âœ… ëª¨ë¸ ì €ì¥ ë° ë¡œë”© ì„±ê³µ")
        return True
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ì €ì¥/ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        logger.info("=== ëª¨ë¸ ì €ì¥ ë° ë¡œë”© í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\n")

def test_feature_importance():
    """íŠ¹ì§• ì¤‘ìš”ë„ í…ŒìŠ¤íŠ¸"""
    
    logger = setup_logger("feature_importance_test", "INFO")
    logger.info("=== íŠ¹ì§• ì¤‘ìš”ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        X_train, y_train, X_val, y_val, X_test, y_test = create_test_dataset()
        
        # ModelTrainer ì´ˆê¸°í™” ë° í›ˆë ¨
        trainer = ModelTrainer()
        
        # Random Forestë§Œ í›ˆë ¨ (íŠ¹ì§• ì¤‘ìš”ë„ ì§€ì›)
        trainer.models["random_forest"].param_grid = {"n_estimators": [50]}
        
        rf_result = trainer.train_single_model("random_forest", X_train, y_train, cv_folds=3)
        
        # íŠ¹ì§• ì¤‘ìš”ë„ ì¶”ì¶œ
        importance_pairs = trainer.get_feature_importance("random_forest")
        
        if importance_pairs is None:
            logger.error("âŒ Random Forest íŠ¹ì§• ì¤‘ìš”ë„ ì¶”ì¶œ ì‹¤íŒ¨")
            return False
        
        if len(importance_pairs) != 30:  # 30ì°¨ì› íŠ¹ì§•
            logger.error(f"âŒ íŠ¹ì§• ì¤‘ìš”ë„ ê°œìˆ˜ ì˜¤ë¥˜: ì˜ˆìƒ 30, ì‹¤ì œ {len(importance_pairs)}")
            return False
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
        importances = [pair[1] for pair in importance_pairs]
        if importances != sorted(importances, reverse=True):
            logger.error("âŒ íŠ¹ì§• ì¤‘ìš”ë„ê°€ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì§€ ì•ŠìŒ")
            return False
        
        logger.info(f"âœ… íŠ¹ì§• ì¤‘ìš”ë„ ì¶”ì¶œ ì„±ê³µ: {len(importance_pairs)}ê°œ íŠ¹ì§•")
        logger.info(f"  ìƒìœ„ 3ê°œ íŠ¹ì§•: {importance_pairs[:3]}")
        
        # SVMì€ íŠ¹ì§• ì¤‘ìš”ë„ê°€ ì—†ì–´ì•¼ í•¨
        svm_importance = trainer.get_feature_importance("svm")
        if svm_importance is not None:
            logger.error("âŒ SVMì—ì„œ íŠ¹ì§• ì¤‘ìš”ë„ê°€ ë°˜í™˜ë¨ (ì˜ˆìƒ: None)")
            return False
        
        logger.info("âœ… SVM íŠ¹ì§• ì¤‘ìš”ë„ ì˜¬ë°”ë¥´ê²Œ None ë°˜í™˜")
        
        logger.info("âœ… íŠ¹ì§• ì¤‘ìš”ë„ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        return True
        
    except Exception as e:
        logger.error(f"íŠ¹ì§• ì¤‘ìš”ë„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        logger.info("=== íŠ¹ì§• ì¤‘ìš”ë„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\n")

def test_training_summary():
    """í›ˆë ¨ ìš”ì•½ ì •ë³´ í…ŒìŠ¤íŠ¸"""
    
    logger = setup_logger("summary_test", "INFO")
    logger.info("=== í›ˆë ¨ ìš”ì•½ ì •ë³´ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        X_train, y_train, X_val, y_val, X_test, y_test = create_test_dataset()
        
        # ModelTrainer ì´ˆê¸°í™” ë° í›ˆë ¨
        trainer = ModelTrainer()
        
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê·¸ë¦¬ë“œ ì¶•ì†Œ
        trainer.models["svm"].param_grid = {"C": [1], "gamma": ["scale"]}
        trainer.models["random_forest"].param_grid = {"n_estimators": [50]}
        
        # ëª¨ë¸ í›ˆë ¨
        all_results = trainer.train_with_cv(X_train, y_train, cv_folds=3)
        
        # í›ˆë ¨ ìš”ì•½ ì •ë³´ ìƒì„±
        summary = trainer.get_training_summary()
        
        # ìš”ì•½ ì •ë³´ ê²€ì¦
        if summary['total_models'] != 2:
            logger.error(f"âŒ ì´ ëª¨ë¸ ìˆ˜ ì˜¤ë¥˜: {summary['total_models']}")
            return False
        
        expected_models = {'svm', 'random_forest'}
        actual_models = set(summary['trained_models'])
        if expected_models != actual_models:
            logger.error(f"âŒ í›ˆë ¨ëœ ëª¨ë¸ ëª©ë¡ ì˜¤ë¥˜: {actual_models}")
            return False
        
        # ê° ëª¨ë¸ì˜ ìš”ì•½ ì •ë³´ í™•ì¸
        for model_type in expected_models:
            if model_type not in summary['training_results']:
                logger.error(f"âŒ {model_type} í›ˆë ¨ ê²°ê³¼ ëˆ„ë½")
                return False
            
            result_summary = summary['training_results'][model_type]
            required_keys = ['best_score', 'best_params', 'training_time', 'n_features', 'n_samples']
            
            for key in required_keys:
                if key not in result_summary:
                    logger.error(f"âŒ {model_type} ìš”ì•½ì—ì„œ {key} ëˆ„ë½")
                    return False
        
        logger.info("âœ… í›ˆë ¨ ìš”ì•½ ì •ë³´:")
        logger.info(f"  ì´ ëª¨ë¸ ìˆ˜: {summary['total_models']}")
        logger.info(f"  í›ˆë ¨ëœ ëª¨ë¸: {summary['trained_models']}")
        
        for model_type, result in summary['training_results'].items():
            logger.info(f"  {model_type}: ì ìˆ˜ {result['best_score']:.4f}, "
                       f"íŠ¹ì§• {result['n_features']}ê°œ, ìƒ˜í”Œ {result['n_samples']}ê°œ")
        
        logger.info("âœ… í›ˆë ¨ ìš”ì•½ ì •ë³´ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        return True
        
    except Exception as e:
        logger.error(f"í›ˆë ¨ ìš”ì•½ ì •ë³´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        logger.info("=== í›ˆë ¨ ìš”ì•½ ì •ë³´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\n")

if __name__ == "__main__":
    logger = setup_logger("main_training_test", "INFO")
    logger.info("ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ í›ˆë ¨ ëª¨ë“ˆ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ğŸ¤–")
    
    test_results = []
    
    # ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_results.append(("ModelTrainer ì´ˆê¸°í™”", test_model_trainer_initialization()))
    test_results.append(("ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨", test_single_model_training()))
    test_results.append(("êµì°¨ ê²€ì¦ í›ˆë ¨", test_cross_validation_training()))
    test_results.append(("ëª¨ë¸ í‰ê°€", test_model_evaluation()))
    test_results.append(("ëª¨ë¸ ì €ì¥/ë¡œë”©", test_model_saving_and_loading()))
    test_results.append(("íŠ¹ì§• ì¤‘ìš”ë„", test_feature_importance()))
    test_results.append(("í›ˆë ¨ ìš”ì•½ ì •ë³´", test_training_summary()))
    
    # ê²°ê³¼ ìš”ì•½
    logger.info("=" * 60)
    logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
        logger.info(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    logger.info("=" * 60)
    success_rate = passed / total * 100
    logger.info(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}/{total} í†µê³¼ ({success_rate:.1f}%)")
    
    if passed == total:
        logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("âœ… ModelTrainer í´ë˜ìŠ¤ê°€ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        logger.info("âœ… êµì°¨ ê²€ì¦ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê°€ ì œëŒ€ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        logger.info("âœ… ëª¨ë¸ ì €ì¥/ë¡œë”© ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        logger.info("âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    logger.info("ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ í›ˆë ¨ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ğŸ¤–")