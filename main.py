#!/usr/bin/env python3
"""
ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì „ì²´ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì„ ì¡°ì •í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤:
1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
2. ëª¨ë¸ í›ˆë ¨
3. ëª¨ë¸ í‰ê°€
4. ëª¨ë¸ ì €ì¥ ë° Core ML ë³€í™˜

design.mdì˜ ëª…ì„¸ì— ë”°ë¼ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import os
import sys
import json
import argparse
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from src.data.pipeline import DataPipeline
from src.ml.training import ModelTrainer
from src.ml.evaluation import ModelEvaluator
from src.ml.model_converter import ModelConverter
from src.utils.logger import setup_logger
from config import DEFAULT_CONFIG


class PipelineCheckpoint:
    """
    íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ë³µì›í•˜ëŠ” ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤.
    """
    
    def __init__(self, checkpoint_dir: str = "checkpoints"):
        """
        ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ìë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        checkpoint_dir : str
            ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(exist_ok=True)
        self.checkpoint_file = self.checkpoint_dir / "pipeline_state.json"
        
    def save_checkpoint(self, step: str, data: Dict[str, Any], 
                       execution_time: float = None):
        """
        í˜„ì¬ íŒŒì´í”„ë¼ì¸ ìƒíƒœë¥¼ ì²´í¬í¬ì¸íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        step : str
            í˜„ì¬ ì‹¤í–‰ ë‹¨ê³„
        data : Dict[str, Any]
            ì €ì¥í•  ë°ì´í„°
        execution_time : float, optional
            ì‹¤í–‰ ì‹œê°„
        """
        checkpoint_data = {
            'step': step,
            'timestamp': datetime.now().isoformat(),
            'execution_time': execution_time,
            'data': data
        }
        
        with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
    
    def load_checkpoint(self) -> Optional[Dict[str, Any]]:
        """
        ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Returns:
        --------
        Optional[Dict[str, Any]]
            ì²´í¬í¬ì¸íŠ¸ ë°ì´í„° ë˜ëŠ” None
        """
        if not self.checkpoint_file.exists():
            return None
        
        try:
            with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return None
    
    def clear_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
        if self.checkpoint_file.exists():
            self.checkpoint_file.unlink()


class WatermelonClassificationPipeline:
    """
    ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ ì‹œìŠ¤í…œì˜ ë©”ì¸ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸.
    
    ì´ í´ë˜ìŠ¤ëŠ” ë‹¤ìŒ ë‹¨ê³„ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤:
    1. ë°ì´í„° ë¡œë”© ë° ì¦ê°•
    2. ëª¨ë¸ í›ˆë ¨
    3. ëª¨ë¸ í‰ê°€
    4. ëª¨ë¸ ì €ì¥ ë° í˜•ì‹ ë³€í™˜
    """
    
    def __init__(self, config=None, checkpoint_dir: str = "checkpoints"):
        """
        íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        config : Config, optional
            êµ¬ì„± ê°ì²´. Noneì´ë©´ ê¸°ë³¸ êµ¬ì„±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        checkpoint_dir : str
            ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
        """
        self.config = config or DEFAULT_CONFIG
        self.logger = setup_logger("WatermelonPipeline", "INFO")
        self.checkpoint_manager = PipelineCheckpoint(checkpoint_dir)
        
        # íŒŒì´í”„ë¼ì¸ êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”
        self.data_pipeline = DataPipeline(self.config)
        self.model_trainer = ModelTrainer(self.config)
        self.model_evaluator = ModelEvaluator(self.config)
        self.model_converter = ModelConverter(self.config)
        
        # ì‹¤í–‰ í†µê³„
        self.pipeline_start_time = None
        self.step_times = {}
        
        self.logger.info("ğŸš€ ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"êµ¬ì„±: {len(self.config.class_names)}ê°œ í´ë˜ìŠ¤, "
                        f"ìƒ˜í”Œë ˆì´íŠ¸ {self.config.sample_rate}Hz")
    
    def step_1_load_data(self, skip_augmentation: bool = False) -> Tuple:
        """
        1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        skip_augmentation : bool
            ë°ì´í„° ì¦ê°•ì„ ê±´ë„ˆë›¸ì§€ ì—¬ë¶€
            
        Returns:
        --------
        Tuple
            (X_train, y_train, X_val, y_val, X_test, y_test)
        """
        step_start_time = time.time()
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘")
        self.logger.info("=" * 60)
        
        try:
            # ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            self.logger.info("ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
            
            pipeline_result = self.data_pipeline.run_complete_pipeline(
                skip_augmentation=skip_augmentation
            )
            
            # ê²°ê³¼ ì¶”ì¶œ
            datasets = pipeline_result['datasets']
            X_train = datasets['train']['features']
            y_train = datasets['train']['labels']
            X_val = datasets['validation']['features']
            y_val = datasets['validation']['labels']
            X_test = datasets['test']['features']
            y_test = datasets['test']['labels']
            
            # ë°ì´í„° í†µê³„ ë¡œê¹…
            self.logger.info(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ:")
            self.logger.info(f"  í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ ìƒ˜í”Œ")
            self.logger.info(f"  ê²€ì¦ ë°ì´í„°: {len(X_val)}ê°œ ìƒ˜í”Œ")
            self.logger.info(f"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ ìƒ˜í”Œ")
            self.logger.info(f"  íŠ¹ì§• ì°¨ì›: {X_train.shape[1] if len(X_train) > 0 else 'N/A'}")
            
            # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
            import numpy as np
            if len(y_train) > 0:
                unique, counts = np.unique(y_train, return_counts=True)
                self.logger.info("  í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
                for i, (cls, count) in enumerate(zip(unique, counts)):
                    class_name = self.config.class_names[int(cls)] if cls < len(self.config.class_names) else f"Class_{cls}"
                    self.logger.info(f"    {class_name}: {count}ê°œ ({count/len(y_train)*100:.1f}%)")
            
            step_time = time.time() - step_start_time
            self.step_times['data_loading'] = step_time
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint_data = {
                'train_samples': len(X_train),
                'val_samples': len(X_val),
                'test_samples': len(X_test),
                'feature_dim': X_train.shape[1] if len(X_train) > 0 else 0,
                'augmentation_skipped': skip_augmentation
            }
            self.checkpoint_manager.save_checkpoint('data_loading', checkpoint_data, step_time)
            
            self.logger.info(f"â±ï¸  1ë‹¨ê³„ ì™„ë£Œ ì‹œê°„: {step_time:.2f}ì´ˆ")
            
            return X_train, y_train, X_val, y_val, X_test, y_test
            
        except Exception as e:
            self.logger.error(f"âŒ 1ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise
    
    def step_2_train_models(self, X_train, y_train, cv_folds: int = 5) -> Dict[str, Any]:
        """
        2ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        X_train : array-like
            í›ˆë ¨ íŠ¹ì§• ë°ì´í„°
        y_train : array-like
            í›ˆë ¨ ë ˆì´ë¸” ë°ì´í„°
        cv_folds : int
            êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜
            
        Returns:
        --------
        Dict[str, Any]
            í›ˆë ¨ ê²°ê³¼
        """
        step_start_time = time.time()
        self.logger.info("=" * 60)
        self.logger.info("ğŸ¤– 2ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        self.logger.info("=" * 60)
        
        try:
            # ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
            self.logger.info(f"êµì°¨ ê²€ì¦ í›ˆë ¨ ì‹œì‘ ({cv_folds}-fold CV)")
            
            training_results = self.model_trainer.train_with_cv(
                X_train, y_train, cv_folds=cv_folds
            )
            
            # í›ˆë ¨ ê²°ê³¼ ë¡œê¹…
            self.logger.info("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ:")
            
            for model_name, result in training_results.items():
                self.logger.info(f"  {model_name.upper()}:")
                self.logger.info(f"    ìµœì  ì ìˆ˜: {result.best_score:.4f}")
                self.logger.info(f"    ìµœì  íŒŒë¼ë¯¸í„°: {result.best_params}")
                self.logger.info(f"    CV ì ìˆ˜ í‰ê· : {result.cv_scores.mean():.4f} Â± {result.cv_scores.std():.4f}")
                self.logger.info(f"    í›ˆë ¨ ì‹œê°„: {result.training_time:.2f}ì´ˆ")
            
            step_time = time.time() - step_start_time
            self.step_times['model_training'] = step_time
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint_data = {
                'models_trained': list(training_results.keys()),
                'best_scores': {name: result.best_score for name, result in training_results.items()},
                'cv_folds': cv_folds
            }
            self.checkpoint_manager.save_checkpoint('model_training', checkpoint_data, step_time)
            
            self.logger.info(f"â±ï¸  2ë‹¨ê³„ ì™„ë£Œ ì‹œê°„: {step_time:.2f}ì´ˆ")
            
            return training_results
            
        except Exception as e:
            self.logger.error(f"âŒ 2ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise
    
    def step_3_evaluate_models(self, X_test, y_test) -> Dict[str, Any]:
        """
        3ë‹¨ê³„: ëª¨ë¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        X_test : array-like
            í…ŒìŠ¤íŠ¸ íŠ¹ì§• ë°ì´í„°
        y_test : array-like
            í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” ë°ì´í„°
            
        Returns:
        --------
        Dict[str, Any]
            í‰ê°€ ê²°ê³¼
        """
        step_start_time = time.time()
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“ˆ 3ë‹¨ê³„: ëª¨ë¸ í‰ê°€ ì‹œì‘")
        self.logger.info("=" * 60)
        
        try:
            # ê°œë³„ ëª¨ë¸ í‰ê°€
            evaluation_results = {}
            
            for model_name, model in self.model_trainer.trained_models.items():
                self.logger.info(f"{model_name.upper()} ëª¨ë¸ í‰ê°€ ì¤‘...")
                
                eval_result = self.model_evaluator.evaluate_model(
                    model, X_test, y_test, model_name
                )
                
                evaluation_results[model_name] = eval_result
                
                # í‰ê°€ ê²°ê³¼ ë¡œê¹…
                metrics = eval_result.classification_metrics
                self.logger.info(f"  ì •í™•ë„: {metrics.accuracy:.4f}")
                self.logger.info(f"  F1-score (macro): {metrics.f1_macro:.4f}")
                self.logger.info(f"  ì •ë°€ë„ (macro): {metrics.precision_macro:.4f}")
                self.logger.info(f"  ì¬í˜„ìœ¨ (macro): {metrics.recall_macro:.4f}")
            
            # ëª¨ë¸ ë¹„êµ
            if len(self.model_trainer.trained_models) >= 2:
                self.logger.info("ëª¨ë¸ ê°„ ì„±ëŠ¥ ë¹„êµ ìˆ˜í–‰ ì¤‘...")
                
                model_names = list(self.model_trainer.trained_models.keys())
                model1_name, model2_name = model_names[0], model_names[1]
                
                comparison_result = self.model_evaluator.compare_models(
                    self.model_trainer.trained_models[model1_name],
                    self.model_trainer.trained_models[model2_name],
                    X_test, y_test, model1_name, model2_name
                )
                
                # ë¹„êµ ê²°ê³¼ ë¡œê¹…
                self.logger.info("ğŸ“Š ëª¨ë¸ ë¹„êµ ê²°ê³¼:")
                self.logger.info(f"  {model1_name} vs {model2_name}")
                self.logger.info(f"  ì •í™•ë„ ì°¨ì´: {comparison_result.accuracy_difference:.4f}")
                self.logger.info(f"  F1-score ì°¨ì´: {comparison_result.f1_difference:.4f}")
                self.logger.info(f"  í†µê³„ì  ìœ ì˜ì„± (ì •í™•ë„): p={comparison_result.accuracy_p_value:.4f}")
                
                evaluation_results['comparison'] = comparison_result
            
            # ì¢…í•© í‰ê°€ ë³´ê³ ì„œ ìƒì„±
            evaluation_report = self.model_evaluator.create_evaluation_report(
                evaluation_results, save_report=True
            )
            
            step_time = time.time() - step_start_time
            self.step_times['model_evaluation'] = step_time
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint_data = {
                'models_evaluated': list(evaluation_results.keys()),
                'best_model': max(evaluation_results.keys(), 
                                key=lambda k: evaluation_results[k].classification_metrics.accuracy 
                                if k != 'comparison' else 0),
                'evaluation_completed': True
            }
            self.checkpoint_manager.save_checkpoint('model_evaluation', checkpoint_data, step_time)
            
            self.logger.info(f"âœ… í‰ê°€ ë³´ê³ ì„œ ì €ì¥: {evaluation_report.report_path}")
            self.logger.info(f"â±ï¸  3ë‹¨ê³„ ì™„ë£Œ ì‹œê°„: {step_time:.2f}ì´ˆ")
            
            return evaluation_results
            
        except Exception as e:
            self.logger.error(f"âŒ 3ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise
    
    def step_4_save_and_convert_models(self, convert_to_coreml: bool = True) -> Dict[str, Any]:
        """
        4ë‹¨ê³„: ëª¨ë¸ ì €ì¥ ë° í˜•ì‹ ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        convert_to_coreml : bool
            Core ML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í• ì§€ ì—¬ë¶€
            
        Returns:
        --------
        Dict[str, Any]
            ë³€í™˜ ê²°ê³¼
        """
        step_start_time = time.time()
        self.logger.info("=" * 60)
        self.logger.info("ğŸ’¾ 4ë‹¨ê³„: ëª¨ë¸ ì €ì¥ ë° ë³€í™˜ ì‹œì‘")
        self.logger.info("=" * 60)
        
        try:
            conversion_results = {}
            
            for model_name, model in self.model_trainer.trained_models.items():
                self.logger.info(f"{model_name.upper()} ëª¨ë¸ ì €ì¥ ì¤‘...")
                
                # Pickle í˜•ì‹ìœ¼ë¡œ ì €ì¥
                model_metadata = {
                    'model_type': model_name,
                    'feature_count': 30,
                    'class_names': self.config.class_names,
                    'training_completed': True
                }
                
                pickle_path = self.model_converter.save_pickle_model(
                    model, model_name, model_metadata
                )
                
                self.logger.info(f"âœ… Pickle ëª¨ë¸ ì €ì¥: {pickle_path}")
                
                # Core ML ë³€í™˜ (ìš”ì²­ëœ ê²½ìš°)
                if convert_to_coreml:
                    try:
                        self.logger.info(f"{model_name.upper()} Core ML ë³€í™˜ ì¤‘...")
                        
                        conversion_result = self.model_converter.convert_model_with_validation(
                            model, model_name, validate=True
                        )
                        
                        conversion_results[model_name] = conversion_result
                        
                        self.logger.info(f"âœ… Core ML ë³€í™˜ ì™„ë£Œ:")
                        self.logger.info(f"  íŒŒì¼: {conversion_result.converted_path}")
                        self.logger.info(f"  í¬ê¸°: {conversion_result.file_size_bytes:,} bytes")
                        self.logger.info(f"  ë³€í™˜ ì‹œê°„: {conversion_result.conversion_time:.3f}ì´ˆ")
                        self.logger.info(f"  ê²€ì¦ í†µê³¼: {conversion_result.validation_passed}")
                        
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ {model_name} Core ML ë³€í™˜ ì‹¤íŒ¨: {e}")
                        self.logger.warning("Pickle í˜•ì‹ ëª¨ë¸ì€ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ë³€í™˜ ìš”ì•½ ìƒì„±
            conversion_summary = self.model_converter.get_conversion_summary()
            
            step_time = time.time() - step_start_time
            self.step_times['model_conversion'] = step_time
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint_data = {
                'pickle_models_saved': len(self.model_trainer.trained_models),
                'coreml_conversions': len(conversion_results),
                'conversion_success_rate': conversion_summary.get('success_rate', 0),
                'conversion_completed': True
            }
            self.checkpoint_manager.save_checkpoint('model_conversion', checkpoint_data, step_time)
            
            self.logger.info(f"ğŸ“Š ë³€í™˜ ìš”ì•½:")
            self.logger.info(f"  ì´ ë³€í™˜: {conversion_summary.get('total_conversions', 0)}ê°œ")
            self.logger.info(f"  ì„±ê³µë¥ : {conversion_summary.get('success_rate', 0):.1%}")
            self.logger.info(f"â±ï¸  4ë‹¨ê³„ ì™„ë£Œ ì‹œê°„: {step_time:.2f}ì´ˆ")
            
            return {
                'conversion_results': conversion_results,
                'conversion_summary': conversion_summary
            }
            
        except Exception as e:
            self.logger.error(f"âŒ 4ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise
    
    def run_complete_pipeline(self, skip_augmentation: bool = False,
                            cv_folds: int = 5, convert_to_coreml: bool = True,
                            resume_from_checkpoint: bool = False) -> Dict[str, Any]:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        skip_augmentation : bool
            ë°ì´í„° ì¦ê°•ì„ ê±´ë„ˆë›¸ì§€ ì—¬ë¶€
        cv_folds : int
            êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜
        convert_to_coreml : bool
            Core ML ë³€í™˜ ìˆ˜í–‰ ì—¬ë¶€
        resume_from_checkpoint : bool
            ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘í• ì§€ ì—¬ë¶€
            
        Returns:
        --------
        Dict[str, Any]
            ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼
        """
        self.pipeline_start_time = time.time()
        
        self.logger.info("ğŸ¯" * 20)
        self.logger.info("ğŸš€ ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ğŸš€")
        self.logger.info("ğŸ¯" * 20)
        self.logger.info(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"êµ¬ì„±: ì¦ê°•ê±´ë„ˆë›°ê¸°={skip_augmentation}, CVí´ë“œ={cv_folds}, CoreMLë³€í™˜={convert_to_coreml}")
        
        # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
        checkpoint = None
        if resume_from_checkpoint:
            checkpoint = self.checkpoint_manager.load_checkpoint()
            if checkpoint:
                self.logger.info(f"ğŸ“‹ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: {checkpoint['step']} ë‹¨ê³„ë¶€í„°")
        
        try:
            pipeline_results = {}
            
            # 1ë‹¨ê³„: ë°ì´í„° ë¡œë”©
            if not checkpoint or checkpoint['step'] in ['data_loading']:
                X_train, y_train, X_val, y_val, X_test, y_test = self.step_1_load_data(skip_augmentation)
                pipeline_results['data_loading'] = {
                    'train_samples': len(X_train),
                    'val_samples': len(X_val),
                    'test_samples': len(X_test)
                }
            else:
                self.logger.info("ğŸ“‹ ë°ì´í„° ë¡œë”© ë‹¨ê³„ ê±´ë„ˆë›°ê¸° (ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µì›)")
                # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ë³µì›í•´ì•¼ í•¨
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í™”ë¥¼ ìœ„í•´ ë‹¤ì‹œ ë¡œë”©
                X_train, y_train, X_val, y_val, X_test, y_test = self.step_1_load_data(skip_augmentation)
            
            # 2ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨
            if not checkpoint or checkpoint['step'] in ['data_loading', 'model_training']:
                training_results = self.step_2_train_models(X_train, y_train, cv_folds)
                pipeline_results['model_training'] = training_results
            else:
                self.logger.info("ğŸ“‹ ëª¨ë¸ í›ˆë ¨ ë‹¨ê³„ ê±´ë„ˆë›°ê¸° (ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µì›)")
            
            # 3ë‹¨ê³„: ëª¨ë¸ í‰ê°€
            if not checkpoint or checkpoint['step'] in ['data_loading', 'model_training', 'model_evaluation']:
                evaluation_results = self.step_3_evaluate_models(X_test, y_test)
                pipeline_results['model_evaluation'] = evaluation_results
            else:
                self.logger.info("ğŸ“‹ ëª¨ë¸ í‰ê°€ ë‹¨ê³„ ê±´ë„ˆë›°ê¸° (ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µì›)")
            
            # 4ë‹¨ê³„: ëª¨ë¸ ë³€í™˜
            conversion_results = self.step_4_save_and_convert_models(convert_to_coreml)
            pipeline_results['model_conversion'] = conversion_results
            
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
            total_time = time.time() - self.pipeline_start_time
            
            self.logger.info("ğŸ‰" * 20)
            self.logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! âœ…")
            self.logger.info("ğŸ‰" * 20)
            self.logger.info(f"ì „ì²´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")
            
            # ë‹¨ê³„ë³„ ì‹œê°„ ìš”ì•½
            if self.step_times:
                self.logger.info("ğŸ“Š ë‹¨ê³„ë³„ ì‹¤í–‰ ì‹œê°„:")
                for step, duration in self.step_times.items():
                    self.logger.info(f"  {step}: {duration:.2f}ì´ˆ ({duration/total_time*100:.1f}%)")
            
            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            pipeline_results['execution_summary'] = {
                'total_time': total_time,
                'step_times': self.step_times,
                'completed_at': datetime.now().isoformat(),
                'success': True
            }
            
            # ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
            self.checkpoint_manager.clear_checkpoint()
            
            return pipeline_results
            
        except Exception as e:
            total_time = time.time() - self.pipeline_start_time
            self.logger.error(f"ğŸ’¥ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            self.logger.error(f"ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")
            
            # ì‹¤íŒ¨ ì‹œì—ë„ ì²´í¬í¬ì¸íŠ¸ëŠ” ìœ ì§€ (ì¬ì‹œì‘ ê°€ëŠ¥)
            raise
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """
        í˜„ì¬ íŒŒì´í”„ë¼ì¸ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
        --------
        Dict[str, Any]
            íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì •ë³´
        """
        checkpoint = self.checkpoint_manager.load_checkpoint()
        
        status = {
            'pipeline_initialized': True,
            'checkpoint_available': checkpoint is not None,
            'components_ready': {
                'data_pipeline': self.data_pipeline is not None,
                'model_trainer': self.model_trainer is not None,
                'model_evaluator': self.model_evaluator is not None,
                'model_converter': self.model_converter is not None
            }
        }
        
        if checkpoint:
            status.update({
                'last_completed_step': checkpoint['step'],
                'last_execution_time': checkpoint.get('execution_time'),
                'last_timestamp': checkpoint['timestamp']
            })
        
        return status


def create_argument_parser():
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    parser = argparse.ArgumentParser(
        description="ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ ì‹œìŠ¤í…œ ë©”ì¸ íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python main.py                              # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  python main.py --skip-augmentation          # ë°ì´í„° ì¦ê°• ì—†ì´ ì‹¤í–‰
  python main.py --cv-folds 10                # 10-fold êµì°¨ ê²€ì¦ ì‚¬ìš©
  python main.py --no-coreml                  # Core ML ë³€í™˜ ê±´ë„ˆë›°ê¸°
  python main.py --resume                     # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘
  python main.py --status                     # íŒŒì´í”„ë¼ì¸ ìƒíƒœë§Œ í™•ì¸
        """
    )
    
    # ì‹¤í–‰ ì˜µì…˜
    parser.add_argument(
        '--skip-augmentation', 
        action='store_true',
        help='ë°ì´í„° ì¦ê°•ì„ ê±´ë„ˆë›°ê³  ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš©'
    )
    
    parser.add_argument(
        '--cv-folds', 
        type=int, 
        default=5,
        help='êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 5)'
    )
    
    parser.add_argument(
        '--no-coreml', 
        action='store_true',
        help='Core ML ë³€í™˜ì„ ê±´ë„ˆë›°ê¸°'
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ê´€ë ¨
    parser.add_argument(
        '--resume', 
        action='store_true',
        help='ì´ì „ ì²´í¬í¬ì¸íŠ¸ì—ì„œ íŒŒì´í”„ë¼ì¸ ì¬ì‹œì‘'
    )
    
    parser.add_argument(
        '--checkpoint-dir', 
        type=str, 
        default='checkpoints',
        help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: checkpoints)'
    )
    
    parser.add_argument(
        '--clear-checkpoint', 
        action='store_true',
        help='ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ'
    )
    
    # ì •ë³´ í™•ì¸
    parser.add_argument(
        '--status', 
        action='store_true',
        help='íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸ë§Œ ìˆ˜í–‰'
    )
    
    parser.add_argument(
        '--dry-run', 
        action='store_true',
        help='ì‹¤ì œ ì‹¤í–‰ ì—†ì´ ì„¤ì •ë§Œ í™•ì¸'
    )
    
    # ë¡œê¹… ì˜µì…˜
    parser.add_argument(
        '--log-level', 
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='ë¡œê·¸ ë ˆë²¨ ì„¤ì • (ê¸°ë³¸ê°’: INFO)'
    )
    
    return parser


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # ë¡œê±° ì„¤ì •
    logger = setup_logger("MainPipeline", args.log_level)
    
    try:
        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        pipeline = WatermelonClassificationPipeline(
            checkpoint_dir=args.checkpoint_dir
        )
        
        # ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬ (ìš”ì²­ëœ ê²½ìš°)
        if args.clear_checkpoint:
            pipeline.checkpoint_manager.clear_checkpoint()
            logger.info("âœ… ì²´í¬í¬ì¸íŠ¸ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        # íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸ (ìš”ì²­ëœ ê²½ìš°)
        if args.status:
            status = pipeline.get_pipeline_status()
            logger.info("ğŸ“Š íŒŒì´í”„ë¼ì¸ ìƒíƒœ:")
            logger.info(f"  ì´ˆê¸°í™”ë¨: {status['pipeline_initialized']}")
            logger.info(f"  ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš© ê°€ëŠ¥: {status['checkpoint_available']}")
            
            if status['checkpoint_available']:
                logger.info(f"  ë§ˆì§€ë§‰ ì™„ë£Œ ë‹¨ê³„: {status['last_completed_step']}")
                logger.info(f"  ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„: {status.get('last_execution_time', 'N/A')}ì´ˆ")
                logger.info(f"  íƒ€ì„ìŠ¤íƒ¬í”„: {status['last_timestamp']}")
            
            components = status['components_ready']
            logger.info("  êµ¬ì„±ìš”ì†Œ ì¤€ë¹„ ìƒíƒœ:")
            for component, ready in components.items():
                status_icon = "âœ…" if ready else "âŒ"
                logger.info(f"    {component}: {status_icon}")
            
            return
        
        # Dry run (ì„¤ì • í™•ì¸ë§Œ)
        if args.dry_run:
            logger.info("ğŸ” Dry run ëª¨ë“œ: ì„¤ì • í™•ì¸ë§Œ ìˆ˜í–‰")
            logger.info(f"  ë°ì´í„° ì¦ê°• ê±´ë„ˆë›°ê¸°: {args.skip_augmentation}")
            logger.info(f"  êµì°¨ ê²€ì¦ í´ë“œ: {args.cv_folds}")
            logger.info(f"  Core ML ë³€í™˜: {not args.no_coreml}")
            logger.info(f"  ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: {args.resume}")
            logger.info(f"  ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬: {args.checkpoint_dir}")
            logger.info("âœ… ì„¤ì • í™•ì¸ ì™„ë£Œ")
            return
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        logger.info("ğŸš€ ìˆ˜ë°• ì†Œë¦¬ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        results = pipeline.run_complete_pipeline(
            skip_augmentation=args.skip_augmentation,
            cv_folds=args.cv_folds,
            convert_to_coreml=not args.no_coreml,
            resume_from_checkpoint=args.resume
        )
        
        # ìµœì¢… ê²°ê³¼ ë¡œê¹…
        execution_summary = results.get('execution_summary', {})
        logger.info("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        logger.info(f"ì´ ì‹¤í–‰ ì‹œê°„: {execution_summary.get('total_time', 0):.2f}ì´ˆ")
        logger.info(f"ì™„ë£Œ ì‹œê°„: {execution_summary.get('completed_at', 'N/A')}")
        
        logger.info("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
        logger.info("  1. results/ ë””ë ‰í† ë¦¬ì—ì„œ í‰ê°€ ë³´ê³ ì„œ í™•ì¸")
        logger.info("  2. models/ ë””ë ‰í† ë¦¬ì—ì„œ ì €ì¥ëœ ëª¨ë¸ í™•ì¸")
        logger.info("  3. docs/COREML_USAGE.mdì—ì„œ Core ML ëª¨ë¸ ì‚¬ìš©ë²• í™•ì¸")
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ íŒŒì´í”„ë¼ì¸ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        logger.info("ğŸ’¡ --resume ì˜µì…˜ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
        
    except Exception as e:
        logger.error(f"ğŸ’¥ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error("ğŸ’¡ --resume ì˜µì…˜ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘í•´ë³´ì„¸ìš”.")
        logger.error("ğŸ’¡ --status ì˜µì…˜ìœ¼ë¡œ í˜„ì¬ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        import traceback
        logger.debug(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()